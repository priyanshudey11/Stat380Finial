---
title: "Final_Project"
author: 
  - "Ahsan Sultan"
  - "Priyanshu Dey" 
  - Janvi Ahuja" 
  - "Daniel Miller"
output: html_document
date: "2024-12-10"
---

1. [Part 1: Data Cleaning and Data Visualization – Complete without Generative AI](#part1)
2. [Part 2: Data Cleaning and Data Visualization – Complete with Generative AI](#part2)
3. [Part 3:Inference ](#part3)
4. [Part 4: Prediction](#part4)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
remove(list = ls())
#Loading in Essential Libraries
library(tidyverse)
library(ggplot2)

#Loading in the Dataxdsw3
CODGames_p1_380 <- read.csv("CODMaps.csv") #589 rows, 27 columns
CODGames_p2_380 <- read.csv("CODGames_p2_380.csv") #250 rows, 27 columns
CODMaps <- read.csv("CODGames_p2_380.csv")
CODGameModes <- read.csv("CODGameModes.csv")
```

# Task 1 - Data Cleaning and Data Visualization   {#part1}
My thought process is that after reading through the Final Project PDF and going over the data csvs I realized that most of the CSVs need some cleansing to do. Since CODGames_p1_380 and CODGames_p2_380 are basically about a player each and their rankings in the online game, I think we should merge the dataframes to make it one more combined dataframe. I also realized that each of the two csvs have null values in the map and choices column so it would be important to remove them to keep all values in check. There are also trailing spaces as highlighted in the document so we would have to remove that also. I think it would be smart to eliminate rows that have missing choice values because they cant determine the winner. My thinking for the map winning criteria was to get unique maps from both map1 and map2 and then count the number of times they appear and then count wins where the map was chosen. Then I would count win from ties when map was map1.

```{r}
### I feel we should double check if we should use rbind or bind_rows
combined <- bind_rows(CODGames_p1_380, CODGames_p2_380)

combined <- combined %>%
  mutate(Map1 = trimws(Map1),
         Map2 = trimws(Map2),
         Choice = trimws(Choice)) %>%
  filter(!is.na(Map1) & !is.na(Map2) & !is.na(Choice)) 
```

### Calculating Map Choices Ratio/Stats
```{r}
calculate_win_stats <- function(data) {

    # Get unique maps
    maps <- data %>%
        select(Map1, Map2) %>%
        unlist() %>%
        unique() %>%
        .[!is.na(.)]
    
    # Initialize results dataframe
    results <- data.frame(
        Map = maps,
        Appearances = 0,
        Regular_Wins = 0,
        Tie_Wins = 0,
        Win_Rate = 0
    )
    
    for (map in maps) {
        # Calculate statistics using pipes
        stats <- data %>%
            summarize(
                appearances = sum(Map1 == map | Map2 == map, na.rm = TRUE),
                regular_wins = sum(Choice == map & 
                                 MapVote != paste(Map1, "to", Map1), 
                                 na.rm = TRUE),
                tie_wins = sum(Map1 == map & 
                             MapVote == paste(Map1, "to", Map1), 
                             na.rm = TRUE)
            )
        
        # Calculate win rate
        total_wins <- stats %>% 
            transmute(total = regular_wins + tie_wins) %>% 
            pull()
        
        win_rate <- round((total_wins / stats$appearances) * 100, 2)
        
        # Update results
        results[results$Map == map,] <- c(map, 
                                        stats$appearances, 
                                        stats$regular_wins,
                                        stats$tie_wins, 
                                        win_rate)
    }
    
    return(results)
}
```


```{r}
maxresults <- calculate_win_stats(combined)
```

### Visualization
```{r}
  # Optional: Remove rows with NA

ggplot(maxresults, aes(x = reorder(Map, Win_Rate), y = Win_Rate)) +
    geom_bar(stat = "identity", fill = "red") +
    coord_flip() +
    theme_minimal() +
    labs(title = "Map Win Rates in Voting",
         x = "Map",
         y = "Win Rate (%)") +
    theme(axis.text.y = element_text(size = 6), axis.text.x = element_text(size=4.5))
```

To answer research question we looked at the graph/chart for the following insights:

Nuketown '84 variants dominate with the highest win rates (Halloween version at 100%, regular version at 82%)
Crossroads Strike shows strong performance with a 77.6% win rate
Raid and Standoff are consistently popular choices, winning 75% and 70% of their appearances respectively

# Task 2 - Data Cleaning and Data Visualization with Generative AI Tool Selection {#part2}

Generative AI Tool Selection

For this task, we utilized ChatGPT (OpenAI GPT-4), known for its advanced natural language processing capabilities.

Prompts Used:
"we need to clean and analyze data from a video game voting dataset. The dataset includes information about two candidate maps (Map1 and Map2) and the final map chosen based on voting (Choice). Some rows include tie-breaking logic, where Map1 is selected by default in ties. our goal is to calculate the probability that each map wins when it is a candidate. Could you help me outline the data cleaning and analysis steps?"
"The dataset has inconsistencies, such as trailing spaces in map names, missing or NA values in Map1, Map2, and Choice, and potential misspellings of map names compared to a reference list in another file (CODMaps.csv)."
"To calculate the win probability for each map:
Count how often each map appears as a candidate (Map1 or Map2).
Count how often each map wins (Choice column).
Include tie-breaking logic where Map1 is selected in a tie. Could you provide R code to implement this logic and calculate win probabilities?"
"Once we calculate the win probabilities, we would like to visualize the results as a bar chart using ggplot2. Could you create R code to plot the maps on the x-axis and their win probabilities on the y-axis, with bars sorted by win probability?"

## Code Generated through AI
```{r}
library(dplyr)
library(ggplot2)
library(tidyr)

game_modes_df <- read.csv("CODGameModes.csv", stringsAsFactors = FALSE)
games_p1_df <- read.csv("CODGames_p1_380.csv", stringsAsFactors = FALSE)
games_p2_df <- read.csv("CODGames_p2_380.csv", stringsAsFactors = FALSE)
maps_df <- read.csv("CODMaps.csv", stringsAsFactors = FALSE)
```

```{r}
games_df <- bind_rows(games_p1_df, games_p2_df)
```

```{r}
# Clean column names and map names
games_df <- games_df %>%
  rename_with(trimws) %>%
  mutate(
    Map1 = trimws(Map1),
    Map2 = trimws(Map2),
    Choice = trimws(Choice)
  )

maps_df <- maps_df %>%
  rename_with(trimws) %>%
  mutate(Name = trimws(Name))

valid_maps <- maps_df$Name
```

```{r}
# Function to correct map names
correct_map_name <- function(map_name, valid_names) {
  if (is.na(map_name)) return(map_name)
  for (valid_name in valid_names) {
    if (tolower(map_name) == tolower(valid_name)) {
      return(valid_name)
    }
  }
  return(map_name)
}

```

```{r}
# Apply the correction function to Map1, Map2, and Choice
games_df <- games_df %>%
  mutate(
    Map1 = sapply(Map1, correct_map_name, valid_names = valid_maps),
    Map2 = sapply(Map2, correct_map_name, valid_names = valid_maps),
    Choice = sapply(Choice, correct_map_name, valid_names = valid_maps)
  )
```

```{r}
# Calculate the total occurrences of each map as a candidate
map_candidate_counts <- games_df %>%
  pivot_longer(cols = c(Map1, Map2), names_to = "Position", values_to = "Map") %>%
  filter(!is.na(Map)) %>%
  count(Map, name = "CandidateCount")
```

```{r}
# Calculate the total wins for each map in the Choice column
map_wins <- games_df %>%
  filter(!is.na(Choice)) %>%
  count(Choice, name = "WinCount")
```

```{r}
# Merge the counts and calculate win probabilities
map_stats <- map_candidate_counts %>%
  full_join(map_wins, by = c("Map" = "Choice")) %>%
  mutate(
    WinCount = replace_na(WinCount, 0),
    WinProbability = WinCount / CandidateCount
  )

```

```{r}
# Sort by WinProbability for visualization
map_stats <- map_stats %>%
  arrange(desc(WinProbability))
```

```{r}
# Visualization
ggplot(map_stats, aes(x = reorder(Map, -WinProbability), y = WinProbability)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = "Win Probability of Maps when Chosen as Candidates",
    x = "Map",
    y = "Win Probability"
  )

# Display results
print(map_stats)
```

Comparison: Generative AI vs. Manual Solution

Both our code and the generative AI solution effectively tackle the task of calculating map win rates, but their approaches have clear differences in methodology, strengths, and weaknesses. Both solutions clean the data to address issues like trailing spaces and missing values and use tidyverse and ggplot2 to produce bar plots that clearly display the win probabilities. While the outcomes are similar, the way each solution achieves these results is notably different.

Our code follows a methodical, step-by-step process. It carefully handles edge cases, such as correcting map names based on a reference dataset and applying tie-breaking logic when Map1 is selected by default. This thorough approach ensures reliability and accuracy, particularly when working with inconsistent or incomplete data. However, the iterative logic used in our code can make it slower when dealing with large datasets. The detailed nature of the code also means it’s slightly longer, but this makes it easier to understand and debug when needed.

The generative AI solution, on the other hand, focuses on speed and simplicity. By using vectorized operations, it processes data more efficiently, which is especially useful for larger datasets. Its compact and streamlined structure makes it quicker to write and implement. However, it relies on initial assumptions about data quality and consistency, which could result in errors when faced with more complex or messy datasets. While the AI-generated code produces polished visualizations and performs well for clean data, it does not address certain edge cases as comprehensively as our code.

In terms of their strengths, our code is highly reliable and accurate, making it better for datasets that require careful handling of inconsistencies. On the other hand, the AI-generated solution is faster and more efficient, excelling when the data is already clean and well-organized. Overall, our code is the better choice when reliability is a priority, especially for datasets with potential issues. However, the generative AI solution is more suitable when speed and efficiency are needed for large-scale data. Combining the thoroughness of our code with the speed of the AI solution would create an ideal balance between reliability and performance.

# Task 3: Inference {#part3}

## Relevant Information

**Research Question:** How does GameType affect TotalXP after accounting for the player's Score?

## Data Cleaning

```{r}
# Clean GameType to merge HC and non-HC variants
combined <- combined %>%
  mutate(GameType = str_remove(GameType, "HC - ")) %>%
  mutate(GameType = str_trim(GameType))
```

## Summary Statistics

Explore the distribution of TotalXP across GameTypes.

```{r}
combined %>%
  group_by(GameType) %>%
  summarize(
    MeanXP = mean(TotalXP, na.rm = TRUE),
    MedianXP = median(TotalXP, na.rm = TRUE),
    Count = n()
  ) %>%
  arrange(desc(MeanXP))
```

## Data Visualization

### Distribution of TotalXP by GameType

```{r}
ggplot(combined, aes(x = GameType, y = TotalXP)) +
  geom_boxplot() +
  theme_minimal() +
  labs(
    title = "Distribution of TotalXP by GameType",
    x = "GameType",
    y = "TotalXP"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Scatter Plot of TotalXP vs. Score by GameType

```{r}
ggplot(combined, aes(x = Score, y = TotalXP, color = GameType)) +
  geom_point(alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "TotalXP vs. Score by GameType",
    x = "Score",
    y = "TotalXP",
    color = "GameType"
  )
```

## Modeling

### Base Model: TotalXP ~ Score + GameType

```{r}
base_model <- lm(TotalXP ~ Score + GameType, data = combined)
summary(base_model)
```

### Improved Model: TotalXP ~ Score * GameType

```{r}

improved_model <- lm(TotalXP ~ Score * GameType, data = combined)
summary(improved_model)

# Ensure residuals and fitted values match the dataset size
combined <- combined %>%
  filter(!is.na(TotalXP) & !is.na(Score)) %>%
  mutate(
    residuals = residuals(improved_model),
    fitted = fitted(improved_model)
  )
```
##### Explanation for the improved model:
The improved model incorporates an interaction term (Score * GameType) to explore whether the relationship between Score and TotalXP varies across different GameTypes. This is based on the idea that some GameTypes may reward specific in-game actions or objectives differently, and these rewards could scale with Score in distinct ways. By including the interaction term, we can investigate how the effect of Score on TotalXP changes depending on the GameType.

## Model Diagnostics: Residual Analysis

#### Residuals vs Fitted Values

```{r}
ggplot(combined, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  )
```

#### QQ Plot for Residual Normality

```{r}
ggplot(combined, aes(sample = residuals)) +
  geom_qq() +
  geom_qq_line(color = "red") +
  theme_minimal() +
  labs(
    title = "QQ Plot of Residuals",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  )
```

## Results and Interpretation

The analysis shows that GameType significantly impacts TotalXP after accounting for the player's Score. GameTypes such as "Domination" yield the highest TotalXP, followed by "Hardpoint" and "TDM," reflecting the differences in objectives and gameplay dynamics. These results align with the expectation that modes requiring more strategic play and longer durations lead to higher TotalXP.

However, the models explain only about 30% of the variation in TotalXP, suggesting other factors, like player skill, time spent in-game, or specific in-game actions, also play a role. Including these variables could improve the model's accuracy. Additionally, the Score-TotalXP relationship may not be strictly linear, and testing non-linear models could provide a better fit.

The interaction terms in the improved model highlight that the effect of Score on TotalXP varies by GameType, but most were not statistically significant. Simplifying the model by focusing only on significant interactions or using advanced methods like random forests may capture these relationships more effectively.

Residual analysis indicates the model assumptions are mostly met, but refining the models with transformations or regression techniques could address issues with the dataset. 

# Task 4: Prediction {#part4}